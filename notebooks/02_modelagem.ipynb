{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c6484c-2b76-4692-bad7-741ea7fba88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas carregadas:\n",
      "Index(['Data', 'Hora (UTC)', 'Temp. Ins. (C)', 'Temp. Max. (C)',\n",
      "       'Temp. Min. (C)', 'Umi. Ins. (%)', 'Umi. Max. (%)', 'Umi. Min. (%)',\n",
      "       'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)', 'Pto Orvalho Min. (C)',\n",
      "       'Pressao Ins. (hPa)', 'Pressao Max. (hPa)', 'Pressao Min. (hPa)',\n",
      "       'Vel. Vento (m/s)', 'Dir. Vento (m/s)', 'Raj. Vento (m/s)',\n",
      "       'Radiacao (KJ/m²)', 'Chuva (mm)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"01/09/2025 30:00\" doesn't match format \"%d/%m/%Y %H:%M\", at position 3. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 3) CRIAÇÃO DA COLUNA DATETIME\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n\u001b[1;32m     70\u001b[0m df_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHora (UTC)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHora (UTC)\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m df_raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHoraCorrigida\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzfill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m:00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m df_raw\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# 4) SELECIONAR SOMENTE O NECESSÁRIO\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"01/09/2025 30:00\" doesn't match format \"%d/%m/%Y %H:%M\", at position 3. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 1) IMPORTS\n",
    "# ==============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "\n",
    "# ==============================================================\n",
    "# 2) CARREGANDO O CSV BRUTO\n",
    "# ==============================================================\n",
    "df_raw = pd.read_csv(\"data/generatedBy_react-csv.csv\", sep=\";\")\n",
    "\n",
    "print(\"Colunas carregadas:\")\n",
    "print(df_raw.columns)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Converter colunas numéricas para float (remove ',')\n",
    "# --------------------------------------------------------------\n",
    "numeric_cols = [\n",
    "    'Temp. Ins. (C)', 'Temp. Max. (C)', 'Temp. Min. (C)',\n",
    "    'Umi. Ins. (%)', 'Umi. Max. (%)', 'Umi. Min. (%)',\n",
    "    'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)', 'Pto Orvalho Min. (C)',\n",
    "    'Pressao Ins. (hPa)', 'Pressao Max. (hPa)', 'Pressao Min. (hPa)',\n",
    "    'Vel. Vento (m/s)', 'Dir. Vento (m/s)', 'Raj. Vento (m/s)',\n",
    "    'Radiacao (KJ/m²)', 'Chuva (mm)'\n",
    "]\n",
    "\n",
    "df_raw[numeric_cols] = (\n",
    "    df_raw[numeric_cols]\n",
    "    .replace(\",\", \".\", regex=True)\n",
    "    .apply(pd.to_numeric, errors=\"coerce\")\n",
    ")\n",
    "\n",
    "# Corrigir valores estranhos na coluna \"Hora (UTC)\"\n",
    "df_raw[\"Hora (UTC)\"] = df_raw[\"Hora (UTC)\"].astype(str)\n",
    "\n",
    "def fix_hour(h):\n",
    "    h = h.strip()\n",
    "\n",
    "    # caso perfeito: 0–23\n",
    "    if h.isdigit() and len(h) <= 2:\n",
    "        return int(h)\n",
    "\n",
    "    # caso com 3 dígitos \"100\" -> \"10\"\n",
    "    if len(h) == 3 and h.isdigit():\n",
    "        return int(h[:-1])\n",
    "\n",
    "    # caso com 4 dígitos \"930\" -> \"9\"\n",
    "    if len(h) == 4 and h.isdigit():\n",
    "        return int(h[:-2])\n",
    "\n",
    "    # fallback: tenta converter\n",
    "    try:\n",
    "        return int(h)\n",
    "    except:\n",
    "        return None  # vira NaN e será ignorado\n",
    "\n",
    "df_raw[\"HoraCorrigida\"] = df_raw[\"Hora (UTC)\"].apply(fix_hour)\n",
    "# Remover horas inválidas (fora do intervalo 0–23)\n",
    "df_raw = df_raw[(df_raw[\"HoraCorrigida\"] >= 0) & (df_raw[\"HoraCorrigida\"] <= 23)]\n",
    "\n",
    "# ==============================================================\n",
    "# 3) CRIAÇÃO DA COLUNA DATETIME\n",
    "# ==============================================================\n",
    "df_raw[\"Hora (UTC)\"] = df_raw[\"Hora (UTC)\"].astype(int)\n",
    "\n",
    "df_raw[\"datetime\"] = pd.to_datetime(\n",
    "    df_raw[\"Data\"] + \" \" + df_raw[\"HoraCorrigida\"].astype(str).str.zfill(2) + \":00\",\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_raw = df_raw.set_index(\"datetime\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# 4) SELECIONAR SOMENTE O NECESSÁRIO\n",
    "# ==============================================================\n",
    "df = df_raw[[\n",
    "    \"Temp. Ins. (C)\",\n",
    "    \"Umi. Ins. (%)\",\n",
    "    \"Vel. Vento (m/s)\",\n",
    "    \"Radiacao (KJ/m²)\",\n",
    "    \"Chuva (mm)\"\n",
    "]].copy()\n",
    "\n",
    "df.columns = [\"Temp\", \"Umi\", \"Vento\", \"Rad\", \"Chuva\"]\n",
    "\n",
    "# ==============================================================\n",
    "# 5) LIMPEZA E INTERPOLAÇÃO\n",
    "# ==============================================================\n",
    "df = df.replace([-9999, -9999.0, 9999, 9999.0], np.nan)\n",
    "df = df.resample(\"H\").mean()\n",
    "df = df.interpolate(method=\"time\")\n",
    "\n",
    "df[\"Rad\"] = df[\"Rad\"].fillna(0)  # Radiação sem leitura vira zero\n",
    "\n",
    "print(\"\\nApós limpeza:\")\n",
    "print(df.head())\n",
    "\n",
    "# ==============================================================\n",
    "# 6) SALVAR DATASET TRATADO\n",
    "# ==============================================================\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "df.to_csv(\"data/dados_tratados.csv\")\n",
    "print(\"\\n✔️ Arquivo salvo em data/dados_tratados.csv\")\n",
    "\n",
    "# ==============================================================\n",
    "# 7) FEATURE ENGINEERING\n",
    "# ==============================================================\n",
    "df_model = df.copy()\n",
    "\n",
    "lags = [1, 2, 3, 6, 12, 24]\n",
    "for lag in lags:\n",
    "    df_model[f\"Temp_lag_{lag}\"] = df_model[\"Temp\"].shift(lag)\n",
    "    df_model[f\"Umi_lag_{lag}\"] = df_model[\"Umi\"].shift(lag)\n",
    "    df_model[f\"Vento_lag_{lag}\"] = df_model[\"Vento\"].shift(lag)\n",
    "    df_model[f\"Rad_lag_{lag}\"] = df_model[\"Rad\"].shift(lag)\n",
    "\n",
    "df_model[\"hour\"] = df_model.index.hour\n",
    "df_model[\"hour_sin\"] = np.sin(2 * np.pi * df_model[\"hour\"] / 24)\n",
    "df_model[\"hour_cos\"] = np.cos(2 * np.pi * df_model[\"hour\"] / 24)\n",
    "\n",
    "# Target → previsão para 1 hora à frente\n",
    "df_model[\"Temp_future_1h\"] = df_model[\"Temp\"].shift(-1)\n",
    "\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "print(\"\\nShape final do dataset de modelagem:\", df_model.shape)\n",
    "\n",
    "# ==============================================================\n",
    "# 8) SEPARAÇÃO TREINO / TESTE\n",
    "# ==============================================================\n",
    "X = df_model.drop(columns=[\"Temp_future_1h\"])\n",
    "y = df_model[\"Temp_future_1h\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nTamanhos:\")\n",
    "print(\"Treino:\", X_train.shape)\n",
    "print(\"Teste:\", X_test.shape)\n",
    "\n",
    "# ==============================================================\n",
    "# 9) FUNÇÃO DE TREINO + MLflow\n",
    "# ==============================================================\n",
    "def treinar_modelo(nome, modelo):\n",
    "\n",
    "    with mlflow.start_run(run_name=nome):\n",
    "\n",
    "        modelo.fit(X_train, y_train)\n",
    "        pred = modelo.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.sklearn.log_model(modelo, nome)\n",
    "\n",
    "        print(f\"\\n===== {nome} =====\")\n",
    "        print(\"RMSE:\", rmse)\n",
    "        print(\"MAE:\", mae)\n",
    "\n",
    "        return pred\n",
    "\n",
    "# ==============================================================\n",
    "# 10) RODAR MODELOS\n",
    "# ==============================================================\n",
    "pred_lr = treinar_modelo(\"LinearRegression\", LinearRegression())\n",
    "pred_rf = treinar_modelo(\"RandomForest\", RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    "))\n",
    "\n",
    "# ==============================================================\n",
    "# 11) PLOT COMPARAÇÃO VISUAL\n",
    "# ==============================================================\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test.values[:200], label=\"Real\")\n",
    "plt.plot(pred_rf[:200], label=\"RandomForest\")\n",
    "plt.legend()\n",
    "plt.title(\"Previsão vs Real\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845e464-e917-4743-96ec-906c2cee1c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
